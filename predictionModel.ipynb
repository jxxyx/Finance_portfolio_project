{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance pandas matplotlib sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am looking at taking the quarterly data from yahoo finance. Doing it from the perspective of a investor. This can be edited into daily data depending on the user's preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will call for the download of data from the Yahoo Finance API. For this, I have fetched both daily and quarterly to allow me to have a clearer picture of the data, and what I can choose to use later on. Currently set ticker to show AAPL only, but user can edit it to fit other companies.\n",
    "\n",
    "Additional thing to note is that we can just use the daily data and convert it to quarterly using the below\n",
    "\n",
    "Resample daily data to quarter-end frequency, taking the last available price of each quarter\n",
    "data_quarterly_alt = data_daily.resample('Q').last()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily data shape: (2516, 5)\n",
      "Price           Close       High        Low       Open     Volume\n",
      "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL\n",
      "Date                                                             \n",
      "2015-01-02  24.320433  24.789802  23.879981  24.778679  212818400\n",
      "2015-01-05  23.635281  24.169160  23.448424  24.089078  257142000\n",
      "2015-01-06  23.637512  23.897778  23.274918  23.699798  263188400\n",
      "2015-01-07  23.968964  24.069065  23.735391  23.846616  160423600\n",
      "2015-01-08  24.889900  24.947738  24.180285  24.298185  237458000\n",
      "Quarterly data shape: (40, 5)\n",
      "Price           Close       High        Low       Open       Volume\n",
      "Ticker           AAPL       AAPL       AAPL       AAPL         AAPL\n",
      "Date                                                               \n",
      "2015-01-01  27.679419  29.719284  23.274913  24.778674  14321762800\n",
      "2015-04-01  28.011990  30.046503  27.491636  27.875760  11315577200\n",
      "2015-07-01  24.735939  29.819925  20.631970  28.458664  15486588000\n",
      "2015-10-01  23.712515  27.893630  23.613393  24.570815  11140271600\n",
      "2016-01-01  24.657894  24.981417  20.902311  23.214484  11315040800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fetch daily historical data for the past 10 years\n",
    "ticker = \"AAPL\"  # Apple Inc. as an example\n",
    "data_daily = yf.download(ticker, start=\"2015-01-01\", end=\"2025-01-01\", interval=\"1d\")\n",
    "print(\"Daily data shape:\", data_daily.shape)\n",
    "print(data_daily.head())\n",
    "\n",
    "# Fetch quarterly historical data for the past 10 years\n",
    "data_quarterly = yf.download(ticker, start=\"2015-01-01\", end=\"2025-01-01\", interval=\"3mo\")\n",
    "print(\"Quarterly data shape:\", data_quarterly.shape)\n",
    "print(data_quarterly.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will drop any rows with missing values and maintain data integrity. Additionally, I only want to make use of adjusted close and volume as it is the simplest feature to understand as a start. This can be edited in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing data (if any)\n",
    "data = data_daily.dropna().copy()\n",
    "\n",
    "# Use only the adjusted close and volume for simplicity in feature creation\n",
    "# safer: check if 'Adj Close' exists, otherwise fallback to 'Close'\n",
    "if 'Adj Close' in data.columns:\n",
    "    data = data[['Adj Close', 'Volume']].rename(columns={'Adj Close': 'AdjClose'})\n",
    "else:\n",
    "    data = data[['Close', 'Volume']].rename(columns={'Close': 'AdjClose'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am labelling the feature to get what I want to see at the end. 1 is for price going up and 0 is price is going down or maintain the same. Practically binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price         AdjClose Target\n",
      "Ticker            AAPL       \n",
      "Date                         \n",
      "2024-12-24  257.916443      1\n",
      "2024-12-26  258.735504      0\n",
      "2024-12-27  255.309296      0\n",
      "2024-12-30  251.923019      0\n",
      "2024-12-31  250.144974      0\n"
     ]
    }
   ],
   "source": [
    "# Create target label: 1 if next period's price is higher than current, else 0\n",
    "data['Target'] = (data['AdjClose'].shift(-1) > data['AdjClose']).astype(int)\n",
    "\n",
    "print(data[['AdjClose', 'Target']].tail(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will be the crucial part, which is the train-test split. This allows for the model to train on a certain amount of data from the whole dataset, and then test what it has trained on the unseen data from the dataset. In this situation, I put 80% of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: 2015-01-02 00:00:00 to 2022-12-28 00:00:00\n",
      "Testing period: 2022-12-29 00:00:00 to 2024-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Assume data is sorted by date ascending\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "print(\"Training period:\", train_data.index[0], \"to\", train_data.index[-1])\n",
    "print(\"Testing period:\", test_data.index[0], \"to\", test_data.index[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the feature engineering portion. \n",
    "\n",
    "I will be crafting a few features from the current available data from the AAPL ticker data that was downloaded earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 1: Recent Price Change (Momentum) –today’s return (percentage change from previous close)\n",
    "\n",
    "Return is the momentum of the current day, and Return_1, Return_2, etc. are the momentum from previous days. We shift them so that on any given day, we only use information from that day or earlier as features (avoiding peeking into the future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\2585287545.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Return'] = train_data['AdjClose'].pct_change() * 100  # percent change\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\2585287545.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Return_1'] = train_data['Return'].shift(1)\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\2585287545.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Return_2'] = train_data['Return'].shift(2)\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\2585287545.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Return_3'] = train_data['Return'].shift(3)\n"
     ]
    }
   ],
   "source": [
    "# Daily percentage return as a feature\n",
    "train_data['Return'] = train_data['AdjClose'].pct_change() * 100  # percent change\n",
    "# Lagged returns for last 3 days as features (to capture short-term momentum)\n",
    "train_data['Return_1'] = train_data['Return'].shift(1)\n",
    "train_data['Return_2'] = train_data['Return'].shift(2)\n",
    "train_data['Return_3'] = train_data['Return'].shift(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 2: Moving Averages (Trend) –  5-day and 20-day moving averages of closing price, and their difference\n",
    "\n",
    "If MA_gap is positive, the short-term average is above the long-term average (an indication of upward momentum, often a “buy” crossover signal in technical analysis). If negative, it might indicate a downtrend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\198833231.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['MA_5'] = train_data['AdjClose'].rolling(window=5).mean()\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\198833231.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['MA_20'] = train_data['AdjClose'].rolling(window=20).mean()\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\198833231.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['MA_gap'] = train_data['MA_5'] - train_data['MA_20']  # difference between short and long MA\n"
     ]
    }
   ],
   "source": [
    "train_data['MA_5'] = train_data['AdjClose'].rolling(window=5).mean()\n",
    "train_data['MA_20'] = train_data['AdjClose'].rolling(window=20).mean()\n",
    "train_data['MA_gap'] = train_data['MA_5'] - train_data['MA_20']  # difference between short and long MA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 3: Volume Change – e.g., volume of previous day or volume percent change\n",
    "\n",
    "I included Volume_change (how much volume changed from yesterday, as a percentage) or simply the previous day’s volume Vol_prev as a feature. The idea is to capture unusual volume spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\934119603.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Volume_change'] = train_data['Volume'].pct_change() * 100\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_12716\\934119603.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Vol_prev'] = train_data['Volume'].shift(1)\n"
     ]
    }
   ],
   "source": [
    "train_data['Volume_change'] = train_data['Volume'].pct_change() * 100\n",
    "train_data['Vol_prev'] = train_data['Volume'].shift(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating these features, remove any rows with NaN (the first few days where moving averages or lagged returns can’t be computed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this portion, we will be using logistic regression, decision tree and random forest as out 3 algorithm to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Return_1' 'Return_2' 'Return_3' 'MA_gap' 'Vol_prev'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m X_train = train_data[[\u001b[33m'\u001b[39m\u001b[33mReturn_1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mReturn_2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mReturn_3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMA_gap\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mVol_prev\u001b[39m\u001b[33m'\u001b[39m]]  \u001b[38;5;66;03m# using a subset of features for example\u001b[39;00m\n\u001b[32m      7\u001b[39m y_train = train_data[\u001b[33m'\u001b[39m\u001b[33mTarget\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_test = \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mReturn_1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mReturn_2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mReturn_3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMA_gap\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVol_prev\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m y_test = test_data[\u001b[33m'\u001b[39m\u001b[33mTarget\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize models\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   3901\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m3902\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   3904\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   3905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2648\u001b[39m, in \u001b[36mMultiIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keyarr) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keyarr[\u001b[32m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m   2646\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m._get_indexer_level_0(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m2648\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[32m   2651\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._get_indexer_strict(key, axis_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2666\u001b[39m, in \u001b[36mMultiIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   2664\u001b[39m cmask = check == -\u001b[32m1\u001b[39m\n\u001b[32m   2665\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cmask.any():\n\u001b[32m-> \u001b[39m\u001b[32m2666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr[cmask]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2667\u001b[39m \u001b[38;5;66;03m# We get here when levels still contain values which are not\u001b[39;00m\n\u001b[32m   2668\u001b[39m \u001b[38;5;66;03m# actually in Index anymore\u001b[39;00m\n\u001b[32m   2669\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Return_1' 'Return_2' 'Return_3' 'MA_gap' 'Vol_prev'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Prepare training data matrices\n",
    "X_train = train_data[['Return_1', 'Return_2', 'Return_3', 'MA_gap', 'Vol_prev']]  # using a subset of features for example\n",
    "y_train = train_data['Target']\n",
    "\n",
    "X_test = test_data[['Return_1', 'Return_2', 'Return_3', 'MA_gap', 'Vol_prev']]\n",
    "y_test = test_data['Target']\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the models\n",
    "log_reg.fit(X_train, y_train)\n",
    "tree.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred_log = log_reg.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc_log = accuracy_score(y_test, pred_log)\n",
    "acc_tree = accuracy_score(y_test, pred_tree)\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_log:.2%}\")\n",
    "print(f\"Decision Tree Accuracy: {acc_tree:.2%}\")\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Buy/Hold/Sell Signals from Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (up) on the test set\n",
    "probs = log_reg.predict_proba(X_test)[:, 1]  # probability of class 1\n",
    "\n",
    "signals = []\n",
    "for p in probs:\n",
    "    if p > 0.6:\n",
    "        signals.append(\"Buy\")   # model very confident the stock will go up\n",
    "    elif p < 0.4:\n",
    "        signals.append(\"Sell\")  # model very confident the stock will go down\n",
    "    else:\n",
    "        signals.append(\"Hold\")  # model isn't sure, so we take no action\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
